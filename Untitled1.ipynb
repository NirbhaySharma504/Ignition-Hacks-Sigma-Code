{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nirbhay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nirbhay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv (r'C:\\Users\\Nirbhay\\Downloads\\training_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>864192</td>\n",
       "      <td>Carly_FTS</td>\n",
       "      <td>I *heart* filling up @dennisschaub desk   1 it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523691</td>\n",
       "      <td>Open_Sourcing</td>\n",
       "      <td>#SocioMat - people create prettier, younger an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>584154</td>\n",
       "      <td>xxcharlx</td>\n",
       "      <td>no way i dont want the tour to end</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1527961</td>\n",
       "      <td>andreapuddu</td>\n",
       "      <td>@HemalRadia Hi Amazing Brother! Sending Limitl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28609</td>\n",
       "      <td>umbec</td>\n",
       "      <td>@flockmaster they are chocolate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>1366175</td>\n",
       "      <td>b13thy</td>\n",
       "      <td>@midderhonz i'm good.. off to buy an electric ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>681828</td>\n",
       "      <td>HeyyitsALison</td>\n",
       "      <td>@StaceyPaha i know..for youngerr boys..what am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>488988</td>\n",
       "      <td>sleepycove</td>\n",
       "      <td>I can't belive it I just got asked for an auto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>985613</td>\n",
       "      <td>AmyyXD</td>\n",
       "      <td>i am putting my bb in the fridge so it cant di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>1410994</td>\n",
       "      <td>esmeretta</td>\n",
       "      <td>lexo wont come visit me</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID           User  \\\n",
       "0        864192      Carly_FTS   \n",
       "1        523691  Open_Sourcing   \n",
       "2        584154       xxcharlx   \n",
       "3       1527961    andreapuddu   \n",
       "4         28609          umbec   \n",
       "...         ...            ...   \n",
       "999995  1366175         b13thy   \n",
       "999996   681828  HeyyitsALison   \n",
       "999997   488988     sleepycove   \n",
       "999998   985613         AmyyXD   \n",
       "999999  1410994      esmeretta   \n",
       "\n",
       "                                                     Text  Sentiment  \n",
       "0       I *heart* filling up @dennisschaub desk   1 it...          1  \n",
       "1       #SocioMat - people create prettier, younger an...          1  \n",
       "2                     no way i dont want the tour to end           0  \n",
       "3       @HemalRadia Hi Amazing Brother! Sending Limitl...          1  \n",
       "4                        @flockmaster they are chocolate           1  \n",
       "...                                                   ...        ...  \n",
       "999995  @midderhonz i'm good.. off to buy an electric ...          1  \n",
       "999996  @StaceyPaha i know..for youngerr boys..what am...          1  \n",
       "999997  I can't belive it I just got asked for an auto...          1  \n",
       "999998  i am putting my bb in the fridge so it cant di...          0  \n",
       "999999                           lexo wont come visit me           0  \n",
       "\n",
       "[1000000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns= ['Text','Sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'].tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Sentiment\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.5, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_X = []\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer= WordNetLemmatizer()\n",
    "\n",
    "for num in range(0, len(X_train)):\n",
    "    \n",
    "    docm = re.sub(r'\\W', ' ', str(X_train[num]))\n",
    "    \n",
    "    docm = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', docm)\n",
    "    \n",
    "    docm = re.sub(r'\\^[a-zA-Z]\\s+', ' ', docm) \n",
    "    \n",
    "    docm = re.sub(r'\\s+', ' ', docm, flags=re.I)\n",
    "    \n",
    "    docm = re.sub(r'^b\\s+', '', docm)\n",
    "    \n",
    "    docm = docm.lower()\n",
    "    \n",
    "    \n",
    "    docm = docm.split()\n",
    "    docm = [stemmer.lemmatize(word) for word in docm]\n",
    "    docm = ' '.join(docm)\n",
    "    \n",
    "    correct_X.append(docm)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer(max_features=5000, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X_train = tfidfconverter.fit_transform(correct_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel = 'linear', C=1.0)\n",
    "X_train1=X_train[:200000]\n",
    "y_train1=y_train[:200000]\n",
    "clf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv (r'C:\\Users\\Nirbhay\\Downloads\\contestant_judgment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(data2, columns= ['Text'])\n",
    "X1 = df1['Text'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = clf.predict(X1)\n",
    "df1['predictions']=y1\n",
    "df1.to_csv('C:\\Users\\Nirbhay\\Downloads\\contestant_judgment_SOLUTION.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
